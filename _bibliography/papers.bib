---
---

@string{aps = {American Physical Society,}}

@misc{qi2025learningreasonparallelsamples,
      title={Learning to Reason Across Parallel Samples for LLM Reasoning}, 
      author={Jianing Qi and Xi Ye and Hao Tang and Zhigang Zhu and Eunsol Choi},
      year={2025},
      eprint={2506.09014},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2506.09014}, 
      selected={true},
      preview={ssa.jpg}
}

@misc{qi2025semanticsrediscoveringspatialawareness,
      title={Beyond Semantics: Rediscovering Spatial Awareness in Vision-Language Models}, 
      author={Jianing Qi and Jiawei Liu and Hao Tang and Zhigang Zhu},
      year={2025},
      eprint={2503.17349},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.17349}, 
      selected={true},
      preview={spatialawareness.jpg}
}

@misc{qi2024verifierqenhancingllmtest,
      title={VerifierQ: Enhancing LLM Test Time Compute with Q-Learning-based Verifiers}, 
      author={Jianing Qi and Hao Tang and Zhigang Zhu},
      year={2024},
      eprint={2410.08048},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.08048}, 
      selected={true},
      preview={verifierq.jpg}
}

@Article{virtualworlds2010004,
AUTHOR = {Qi, Jianing and Tang, Hao and Zhu, Zhigang},
TITLE = {Exploring an Affective and Responsive Virtual Environment to Improve Remote Learning},
JOURNAL = {Virtual Worlds},
VOLUME = {2},
year = {2023},
NUMBER = {1},
PAGES = {53--74},
URL = {https://www.mdpi.com/2813-2084/2/1/4},
ISSN = {2813-2084},
ABSTRACT = {Online classes are typically conducted by using video conferencing software such as Zoom, Microsoft Teams, and Google Meet. Research has identified drawbacks of online learning, such as “Zoom fatigue”, characterized by distractions and lack of engagement. This study presents the CUNY Affective and Responsive Virtual Environment (CARVE) Hub, a novel virtual reality hub that uses a facial emotion classification model to generate emojis for affective and informal responsive interaction in a 3D virtual classroom setting. A web-based machine learning model is employed for facial emotion classification, enabling students to communicate four basic emotions live through automated web camera capture in a virtual classroom without activating their cameras. The experiment is conducted in undergraduate classes on both Zoom and CARVE, and the results of a survey indicate that students have a positive perception of interactions in the proposed virtual classroom compared with Zoom. Correlations between automated emojis and interactions are also observed. This study discusses potential explanations for the improved interactions, including a decrease in pressure on students when they are not showing faces. In addition, video panels in traditional remote classrooms may be useful for communication but not for interaction. Students favor features in virtual reality, such as spatial audio and the ability to move around, with collaboration being identified as the most helpful feature.},
DOI = {10.3390/virtualworlds2010004},
preview={virtualworld.jpg}
}

